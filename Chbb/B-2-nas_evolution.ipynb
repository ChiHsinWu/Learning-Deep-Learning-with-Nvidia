{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hkZZlMIZGexk"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Lambda\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import MaxPooling2D\n","import numpy as np\n","import logging\n","import copy\n","import random\n","tf.get_logger().setLevel(logging.ERROR)\n","\n","MAX_MODEL_SIZE = 500000\n","CANDIDATE_EVALUATIONS = 500\n","EVAL_EPOCHS = 3\n","FINAL_EPOCHS = 20\n","POPULATION_SIZE = 50\n","\n","layer_types = ['DENSE', 'CONV2D', 'MAXPOOL2D']\n","param_values = dict([('size', [16, 64, 256, 1024, 4096]),\n","                ('activation', ['relu', 'tanh', 'elu']),\n","                ('kernel_size', [(1, 1), (2, 2), (3, 3), (4, 4)]),\n","                ('stride', [(1, 1), (2, 2), (3, 3), (4, 4)]),\n","                ('dropout', [0.0, 0.4, 0.7, 0.9])])\n","\n","layer_params = dict([('DENSE', ['size', 'activation', 'dropout']),\n","                     ('CONV2D', ['size', 'activation',\n","                                 'kernel_size', 'stride',\n","                                 'dropout']),\n","                     ('MAXPOOL2D', ['kernel_size', 'stride',\n","                                    'dropout'])])\n","\n","# 載入資料集\n","cifar_dataset = keras.datasets.cifar10\n","(train_images, train_labels), (test_images,\n","                    test_labels) = cifar_dataset.load_data()\n","\n","# 標準化各樣本\n","mean = np.mean(train_images)\n","stddev = np.std(train_images)\n","train_images = (train_images - mean) / stddev\n","test_images = (test_images - mean) / stddev\n","\n","# 將標籤轉為 one-hot 編碼\n","train_labels = to_categorical(train_labels,\n","                              num_classes=10)\n","test_labels = to_categorical(test_labels,\n","                             num_classes=10)\n","\n","#生成模型架構草案的相關函式\n","def generate_random_layer(layer_type):\n","    layer = {}\n","    layer['layer_type'] = layer_type\n","    params = layer_params[layer_type]\n","    for param in params:\n","        values = param_values[param]\n","        layer[param] = values[np.random.randint(0, len(values))]\n","    return layer\n","\n","def generate_model_definition():\n","    layer_count = np.random.randint(2, 9)\n","    non_dense_count = np.random.randint(1, layer_count)\n","    layers = []\n","    for i in range(layer_count):\n","        if i < non_dense_count:\n","            layer_type = layer_types[np.random.randint(1, 3)]\n","            layer = generate_random_layer(layer_type)\n","        else:\n","            layer = generate_random_layer('DENSE')\n","        layers.append(layer)\n","    return layers\n","\n","def compute_weight_count(layers):\n","    last_shape = (32, 32, 3)\n","    total_weights = 0\n","    for layer in layers:\n","        layer_type = layer['layer_type']\n","        if layer_type == 'DENSE':\n","            size = layer['size']\n","            weights = size * (np.prod(last_shape) + 1)\n","            last_shape = (layer['size'])\n","        else:\n","            stride = layer['stride']\n","            if layer_type == 'CONV2D':\n","                size = layer['size']\n","                kernel_size = layer['kernel_size']\n","                weights = size * ((np.prod(kernel_size) *\n","                                   last_shape[2]) + 1)\n","                last_shape = (np.ceil(last_shape[0]/stride[0]),\n","                              np.ceil(last_shape[1]/stride[1]),\n","                              size)\n","            elif layer_type == 'MAXPOOL2D':\n","                weights = 0\n","                last_shape = (np.ceil(last_shape[0]/stride[0]),\n","                              np.ceil(last_shape[1]/stride[1]),\n","                              last_shape[2])\n","        total_weights += weights\n","    total_weights += ((np.prod(last_shape) + 1) * 10)\n","    return total_weights\n","\n","# 根據架構草案來建構模型、然後評估的函式\n","def add_layer(model, params, prior_type):\n","    layer_type = params['layer_type']\n","    if layer_type == 'DENSE':\n","        if prior_type != 'DENSE':\n","            model.add(Flatten())\n","        size = params['size']\n","        act = params['activation']\n","        model.add(Dense(size, activation=act))\n","    elif layer_type == 'CONV2D':\n","        size = params['size']\n","        act = params['activation']\n","        kernel_size = params['kernel_size']\n","        stride = params['stride']\n","        model.add(Conv2D(size, kernel_size, activation=act,\n","                         strides=stride, padding='same'))\n","    elif layer_type == 'MAXPOOL2D':\n","        kernel_size = params['kernel_size']\n","        stride = params['stride']\n","        model.add(MaxPooling2D(pool_size=kernel_size,\n","                               strides=stride, padding='same'))\n","    dropout = params['dropout']\n","    if(dropout > 0.0):\n","        model.add(Dropout(dropout))\n","\n","def create_model(layers):\n","    tf.keras.backend.clear_session()\n","    model = Sequential()\n","    model.add(Lambda(lambda x: x, input_shape=(32, 32, 3)))\n","    prev_layer = 'LAMBDA' # Dummy layer to set input_shape\n","    for layer in layers:\n","        add_layer(model, layer, prev_layer)\n","        prev_layer = layer['layer_type']\n","    model.add(Dense(10, activation='softmax'))\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","def create_and_evaluate_model(model_definition):\n","    weight_count = compute_weight_count(model_definition)\n","    if weight_count > MAX_MODEL_SIZE:\n","        return 0.0\n","    model = create_model(model_definition)\n","    history = model.fit(train_images, train_labels,\n","                        validation_data=(test_images, test_labels),\n","                        epochs=EVAL_EPOCHS, batch_size=64,\n","                        verbose=2, shuffle=False)\n","    acc = history.history['val_accuracy'][-1]\n","    print('Size: ', weight_count)\n","    print('Accuracy: %5.2f' %acc)\n","    return acc\n","\n","# 進化法輔助函式\n","def tweak_model(model_definition):\n","    layer_num = np.random.randint(0, len(model_definition))\n","    last_layer = len(model_definition) - 1\n","    for first_dense, layer in enumerate(model_definition):\n","        if layer['layer_type'] == 'DENSE':\n","            break\n","    if np.random.randint(0, 2) == 1:\n","        delta = 1\n","    else:\n","        delta = -1\n","    if np.random.randint(0, 2) == 1:\n","        # 加/減層\n","        if len(model_definition) < 3:\n","            delta = 1 # 該架構不允許減層\n","        if delta == -1:\n","            # # 減層\n","            if layer_num == 0 and first_dense == 1:\n","                layer_num += 1 # 非密集層至少要一道\n","            if layer_num == first_dense and layer_num == last_layer:\n","                layer_num -= 1 # 密集層至少要一道\n","            del model_definition[layer_num]\n","        else:\n","            # 加層\n","            if layer_num < first_dense:\n","                layer_type = layer_types[np.random.randint(1, 3)]\n","            else:\n","                layer_type = 'DENSE'\n","            layer = generate_random_layer(layer_type)\n","            model_definition.insert(layer_num, layer)\n","    else:\n","        # 調整參數\n","        layer = model_definition[layer_num]\n","        layer_type = layer['layer_type']\n","        params = layer_params[layer_type]\n","        param = params[np.random.randint(0, len(params))]\n","        current_val = layer[param]\n","        values = param_values[param]\n","        index = values.index(current_val)\n","        max_index = len(values)\n","        new_val = values[(index + delta) % max_index]\n","        layer[param] = new_val\n"]},{"cell_type":"markdown","metadata":{"id":"13JF9PdIGexm"},"source":["程式 B-7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CyX-lrltGexo"},"outputs":[],"source":["# 進化演算法輔助函式\n","def cross_over(parents):\n","    # 將一親代的前半段與另一親代的後半段結合成子代\n","    # 若兩親代規模都很小，就乾脆把兩邊前半段結合、後半段也結合，再串接成子代\n","\n","    bottoms = [[], []]\n","    tops = [[], []]\n","    for i, model in enumerate(parents):\n","        for layer in model:\n","            if layer['layer_type'] != 'DENSE':\n","                bottoms[i].append(copy.deepcopy(layer))\n","            else:\n","                tops[i].append(copy.deepcopy(layer))\n","\n","    i = np.random.randint(0, 2)\n","    if (i == 1 and compute_weight_count(parents[0]) +\n","        compute_weight_count(parents[1]) < MAX_MODEL_SIZE):\n","        i = np.random.randint(0, 2)\n","        new_model = bottoms[i] + bottoms[(i+1)%2]\n","        i = np.random.randint(0, 2)\n","        new_model = new_model + tops[i] + tops[(i+1)%2]\n","    else:\n","        i = np.random.randint(0, 2)\n","        new_model = bottoms[i] + tops[(i+1)%2]\n","    return new_model\n","\n","# 設定進化演算法的亂數種子\n","np.random.seed(7)\n","\n","# 生成第一批親代架構\n","population = []\n","for i in range(POPULATION_SIZE):\n","    valid_model = False\n","    while(valid_model == False):\n","        model_definition = generate_model_definition()\n","        acc = create_and_evaluate_model(model_definition)\n","        if acc > 0.0:\n","            valid_model = True\n","    population.append((acc, model_definition))\n","\n","# 進化過程\n","generations = int(CANDIDATE_EVALUATIONS / POPULATION_SIZE) - 1\n","for i in range(generations):\n","    # 隨機兩兩結合成新子代\n","    print('Generation number: ', i)\n","    for j in range(POPULATION_SIZE):\n","        valid_model = False\n","        while(valid_model == False):\n","            rand = np.random.rand()\n","            parents = random.sample(\n","                population[:POPULATION_SIZE], 2)\n","            parents = [parents[0][1], parents[1][1]]\n","            if rand < 0.5:\n","                child = copy.deepcopy(parents[0])\n","                tweak_model(child)\n","            elif rand < 0.75:\n","                child = cross_over(parents)\n","            else:\n","                child = cross_over(parents)\n","                tweak_model(child)\n","            acc = create_and_evaluate_model(child)\n","            if acc > 0.0:\n","                valid_model = True\n","        population.append((acc, child))\n","\n","    # 表現最佳的一批保留，最差的一批去掉，剩下的隨機挑選\n","    population.sort(key=lambda x:x[0])\n","    print('Evolution, best accuracy: %5.2f' %population[-1][0])\n","    top = np.int64(np.ceil(0.2*len(population)))\n","    bottom = np.int64(np.ceil(0.3*len(population)))\n","    top_individuals = population[-top:]\n","    remaining = np.int64(len(population)/2) - len(top_individuals)\n","    population = random.sample(population[bottom:-top],\n","                               remaining) + top_individuals\n","\n","best_model = population[-1][1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLR-ylMbGexq"},"outputs":[],"source":["# 將最後脫穎而出的模型充分訓練、進行最後評估\n","model = create_model(best_model)\n","model.summary()\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam', metrics=['accuracy'])\n","history = model.fit(\n","    train_images, train_labels, validation_data =\n","    (test_images, test_labels), epochs=FINAL_EPOCHS, batch_size=64,\n","    verbose=2, shuffle=True)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}